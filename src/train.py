import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
import joblib
import os

# 1. Configurar rutas
current_dir = os.path.dirname(__file__)
data_path = os.path.join(current_dir, '../data/BrFlights2.csv')
model_path = os.path.join(current_dir, 'flight_model_v2.joblib')

print("Cargando datos...")
try:
    df = pd.read_csv(data_path, encoding='latin1', low_memory=False)
except FileNotFoundError:
    print("❌ Error: No encuentro el CSV BrFlights2.csv en la carpeta data/")
    exit()

# 2. Limpieza y Target
df = df[df['Situacao.Voo'] == 'Realizado']
cols = ['Companhia.Aerea', 'Aeroporto.Origem', 'Aeroporto.Destino', 'Partida.Prevista', 'Partida.Real']
df = df[cols].dropna()

df['Partida.Prevista'] = pd.to_datetime(df['Partida.Prevista'])
df['Partida.Real'] = pd.to_datetime(df['Partida.Real'])
df['delay_minutes'] = (df['Partida.Real'] - df['Partida.Prevista']).dt.total_seconds() / 60
df['target'] = np.where(df['delay_minutes'] > 15, 1, 0)

# 3. Feature Engineering (EL SECRETO DEL ÉXITO)
print("Generando variables...")
df['hora_partida'] = df['Partida.Prevista'].dt.hour
df['dia_semana'] = df['Partida.Prevista'].dt.dayofweek
df['mes'] = df['Partida.Prevista'].dt.month
df['dia_mes'] = df['Partida.Prevista'].dt.day

# Renombrar
df = df.rename(columns={'Companhia.Aerea': 'companhia', 'Aeroporto.Origem': 'origem', 'Aeroporto.Destino': 'destino'})

# Variables nuevas
df['es_fin_semana'] = df['dia_semana'].isin([5, 6]).astype(int)
df['es_hora_pico'] = df['hora_partida'].isin([6,7,8,9,17,18,19,20]).astype(int)
df['temporada_alta'] = df['mes'].isin([1,2,7,12]).astype(int)
df['fin_inicio_mes'] = df['dia_mes'].isin(list(range(1,6)) + list(range(26,32))).astype(int)

# --- ESTADÍSTICAS HISTÓRICAS (Para exportar a la API) ---
# Calculamos medias para usarlas luego. Convertimos a dict para acceso rápido
stats_companhia = df.groupby('companhia')['delay_minutes'].mean().to_dict()
stats_ruta = df.groupby(['origem', 'destino'])['delay_minutes'].mean().to_dict()
stats_hora = df.groupby('hora_partida')['target'].mean().to_dict()

# Aplicamos al dataset de entrenamiento
df['airline_avg_delay'] = df['companhia'].map(stats_companhia)
df['route_avg_delay'] = df.set_index(['origem', 'destino']).index.map(stats_ruta)
df['hour_delay_rate'] = df['hora_partida'].map(stats_hora)

# Llenar nulos con promedios generales
df = df.fillna(0)

# 4. Encoding
le_companhia = LabelEncoder()
le_origem = LabelEncoder()
le_destino = LabelEncoder()

df['companhia_encoded'] = le_companhia.fit_transform(df['companhia'].astype(str))
df['origem_encoded'] = le_origem.fit_transform(df['origem'].astype(str))
df['destino_encoded'] = le_destino.fit_transform(df['destino'].astype(str))

# 5. Entrenamiento XGBoost
features = [
    'companhia_encoded', 'origem_encoded', 'destino_encoded',
    'hora_partida', 'dia_semana', 'mes', 
    'es_fin_semana', 'es_hora_pico', 'temporada_alta', 'fin_inicio_mes',
    'airline_avg_delay', 'route_avg_delay', 'hour_delay_rate'
]

X = df[features]
y = df['target']

# Parámetros optimizados que encontró Claude
print("Entrenando XGBoost Optimizado...")
scale_pos_weight = (y == 0).sum() / (y == 1).sum()
model = xgb.XGBClassifier(
    n_estimators=100, 
    max_depth=8, 
    learning_rate=0.01, 
    subsample=0.7, 
    colsample_bytree=0.8,
    scale_pos_weight=scale_pos_weight,
    random_state=42,
    n_jobs=-1
)
model.fit(X, y)

# 6. Guardar Todo (Modelo + Estadísticas + Encoders)
artifacts = {
    'model': model,
    'features': features,
    'encoders': {
        'companhia': le_companhia,
        'origem': le_origem,
        'destino': le_destino
    },
    'stats': {
        'companhia': stats_companhia,
        'ruta': stats_ruta,
        'hora': stats_hora
    },
    'threshold': 0.53 # El umbral optimizado
}

joblib.dump(artifacts, model_path)
print(f"✅ Modelo V2 guardado en: {model_path}")