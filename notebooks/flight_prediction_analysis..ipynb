{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsSmDaWGk45K",
        "outputId": "014c5a9a-d21f-43ec-f5ca-8c98e986e2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "CARGANDO Y PREPARANDO DATOS...\n",
            "======================================================================\n",
            "✓ Filas originales: 31,437\n",
            "✓ Filas después de limpieza: 24,556\n",
            "✓ Desbalance: {0: 0.8636585763153608, 1: 0.1363414236846392}\n",
            "\n",
            "======================================================================\n",
            "CREANDO FEATURES AVANZADAS...\n",
            "======================================================================\n",
            "  → Calculando estadísticas históricas por aerolínea...\n",
            "  → Calculando estadísticas por ruta...\n",
            "  → Calculando estadísticas por aeropuerto origen...\n",
            "  → Calculando estadísticas por hora del día...\n",
            "  → Creando variables de interacción...\n",
            "✓ Total de features creadas: 31\n",
            "\n",
            "======================================================================\n",
            "CODIFICANDO VARIABLES CATEGÓRICAS...\n",
            "======================================================================\n",
            "✓ Training set: 19,644 samples\n",
            "✓ Test set: 4,912 samples\n",
            "✓ Total features: 25\n",
            "\n",
            "======================================================================\n",
            "ENTRENANDO Y COMPARANDO MODELOS...\n",
            "======================================================================\n",
            "\n",
            "[1/4] Random Forest con búsqueda de hiperparámetros...\n",
            "  ✓ Mejor F1 (CV): 0.4505\n",
            "  ✓ Mejores parámetros: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_depth': 15, 'class_weight': 'balanced_subsample'}\n",
            "\n",
            "[2/4] XGBoost con búsqueda de hiperparámetros...\n",
            "  ✓ Mejor F1 (CV): 0.4335\n",
            "  ✓ Mejores parámetros: {'subsample': 0.7, 'scale_pos_weight': np.float64(6.335324869305452), 'n_estimators': 100, 'max_depth': 8, 'learning_rate': 0.01, 'colsample_bytree': 0.8}\n",
            "\n",
            "[3/4] LightGBM con búsqueda de hiperparámetros...\n",
            "  ✓ Mejor F1 (CV): 0.4304\n",
            "  ✓ Mejores parámetros: {'subsample': 0.8, 'num_leaves': 50, 'n_estimators': 300, 'max_depth': -1, 'learning_rate': 0.05, 'colsample_bytree': 0.8, 'class_weight': 'balanced'}\n",
            "\n",
            "[4/4] Logistic Regression (baseline rápido)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Modelo entrenado\n",
            "\n",
            "======================================================================\n",
            "EVALUANDO MODELOS EN TEST SET...\n",
            "======================================================================\n",
            "\n",
            "Random Forest:\n",
            "  F1-Score: 0.4541\n",
            "  Precision: 0.4148\n",
            "  Recall: 0.5015\n",
            "  ROC-AUC: 0.7938\n",
            "  Accuracy: 0.8355\n",
            "\n",
            "XGBoost:\n",
            "  F1-Score: 0.4627\n",
            "  Precision: 0.3599\n",
            "  Recall: 0.6478\n",
            "  ROC-AUC: 0.8059\n",
            "  Accuracy: 0.7948\n",
            "\n",
            "LightGBM:\n",
            "  F1-Score: 0.4530\n",
            "  Precision: 0.3611\n",
            "  Recall: 0.6075\n",
            "  ROC-AUC: 0.8000\n",
            "  Accuracy: 0.7999\n",
            "\n",
            "Logistic Regression:\n",
            "  F1-Score: 0.3763\n",
            "  Precision: 0.2611\n",
            "  Recall: 0.6731\n",
            "  ROC-AUC: 0.7537\n",
            "  Accuracy: 0.6956\n",
            "\n",
            "======================================================================\n",
            "RANKING DE MODELOS:\n",
            "======================================================================\n",
            "             Modelo  F1-Score  Precision   Recall  ROC-AUC  Accuracy\n",
            "            XGBoost  0.462687   0.359867 0.647761 0.805910  0.794788\n",
            "      Random Forest  0.454054   0.414815 0.501493 0.793843  0.835505\n",
            "           LightGBM  0.452977   0.361136 0.607463 0.799958  0.799878\n",
            "Logistic Regression  0.376304   0.261146 0.673134 0.753720  0.695643\n",
            "\n",
            "======================================================================\n",
            "OPTIMIZANDO THRESHOLD PARA: XGBoost\n",
            "======================================================================\n",
            "✓ Threshold óptimo: 0.5314\n",
            "✓ F1-Score óptimo: 0.4850\n",
            "\n",
            "--- COMPARACIÓN: Default (0.5) vs Optimizado ---\n",
            "\n",
            "Threshold 0.5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9363    0.8180    0.8732      4242\n",
            "           1     0.3599    0.6478    0.4627       670\n",
            "\n",
            "    accuracy                         0.7948      4912\n",
            "   macro avg     0.6481    0.7329    0.6679      4912\n",
            "weighted avg     0.8577    0.7948    0.8172      4912\n",
            "\n",
            "\n",
            "Threshold 0.5314:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9321    0.8604    0.8948      4242\n",
            "           1     0.4056    0.6030    0.4850       670\n",
            "\n",
            "    accuracy                         0.8253      4912\n",
            "   macro avg     0.6688    0.7317    0.6899      4912\n",
            "weighted avg     0.8603    0.8253    0.8389      4912\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ANÁLISIS DETALLADO Y FEATURE IMPORTANCE\n",
            "======================================================================\n",
            "\n",
            "Matriz de Confusión (threshold optimizado):\n",
            "[[3650  592]\n",
            " [ 266  404]]\n",
            "\n",
            "Verdaderos Negativos: 3,650\n",
            "Falsos Positivos: 592\n",
            "Falsos Negativos: 266\n",
            "Verdaderos Positivos: 404\n",
            "\n",
            "Top 15 Features Más Importantes:\n",
            "                 feature  importance\n",
            "        route_delay_rate    0.184993\n",
            "                 dia_mes    0.106266\n",
            "          fin_inicio_mes    0.063365\n",
            "      airline_delay_rate    0.051063\n",
            "         route_avg_delay    0.047345\n",
            "      airline_popularity    0.047275\n",
            "       origin_delay_rate    0.041837\n",
            "         hour_delay_rate    0.034747\n",
            "companhia_origen_encoded    0.032879\n",
            "          origin_traffic    0.031444\n",
            "       airline_std_delay    0.030950\n",
            "       airline_avg_delay    0.029694\n",
            "            hora_partida    0.028910\n",
            "          origem_encoded    0.028424\n",
            "              dia_semana    0.027691\n",
            "\n",
            "======================================================================\n",
            "GUARDANDO MODELO Y ARTEFACTOS...\n",
            "======================================================================\n",
            "✓ Modelo guardado en: flight_model_optimized_v2.joblib\n",
            "✓ Comparación guardada en: model_comparison_results.csv\n",
            "\n",
            "======================================================================\n",
            "¡PROCESO COMPLETADO EXITOSAMENTE!\n",
            "======================================================================\n",
            "\n",
            "Modelo final: XGBoost\n",
            "F1-Score: 0.4627\n",
            "Recall: 0.6478\n",
            "Precision: 0.3599\n",
            "Threshold: 0.5314\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,\n",
        "                             precision_recall_curve, f1_score, roc_curve)\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 1: CARGA Y PREPROCESAMIENTO INICIAL\n",
        "# ============================================================================\n",
        "print(\"=\" * 70)\n",
        "print(\"CARGANDO Y PREPARANDO DATOS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "df = pd.read_csv('/content/BrFlights2.csv', encoding='latin1', low_memory=False)\n",
        "print(f\"✓ Filas originales: {df.shape[0]:,}\")\n",
        "\n",
        "# Filtrado y selección de columnas\n",
        "df = df[df['Situacao.Voo'] == 'Realizado']\n",
        "cols_to_keep = ['Companhia.Aerea', 'Aeroporto.Origem', 'Aeroporto.Destino',\n",
        "                'Partida.Prevista', 'Partida.Real']\n",
        "df = df[cols_to_keep].dropna()\n",
        "\n",
        "# Conversión de fechas y creación de target\n",
        "df['Partida.Prevista'] = pd.to_datetime(df['Partida.Prevista'])\n",
        "df['Partida.Real'] = pd.to_datetime(df['Partida.Real'])\n",
        "df['delay_minutes'] = (df['Partida.Real'] - df['Partida.Prevista']).dt.total_seconds() / 60\n",
        "df['target'] = np.where(df['delay_minutes'] > 15, 1, 0)\n",
        "\n",
        "# Features básicas temporales\n",
        "df['hora_partida'] = df['Partida.Prevista'].dt.hour\n",
        "df['dia_semana'] = df['Partida.Prevista'].dt.dayofweek\n",
        "df['mes'] = df['Partida.Prevista'].dt.month\n",
        "df['dia_mes'] = df['Partida.Prevista'].dt.day\n",
        "\n",
        "# Renombrar\n",
        "df = df.rename(columns={\n",
        "    'Companhia.Aerea': 'companhia',\n",
        "    'Aeroporto.Origem': 'origem',\n",
        "    'Aeroporto.Destino': 'destino'\n",
        "})\n",
        "\n",
        "print(f\"✓ Filas después de limpieza: {df.shape[0]:,}\")\n",
        "print(f\"✓ Desbalance: {df['target'].value_counts(normalize=True).to_dict()}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 2: FEATURE ENGINEERING AVANZADO\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CREANDO FEATURES AVANZADAS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# 2.1 VARIABLES TEMPORALES MEJORADAS\n",
        "df['es_fin_semana'] = df['dia_semana'].isin([5, 6]).astype(int)\n",
        "df['es_lunes'] = (df['dia_semana'] == 0).astype(int)\n",
        "df['es_viernes'] = (df['dia_semana'] == 4).astype(int)\n",
        "\n",
        "# Horas pico (6-9am y 5-8pm)\n",
        "df['es_hora_pico'] = df['hora_partida'].isin([6,7,8,9,17,18,19,20]).astype(int)\n",
        "df['es_madrugada'] = df['hora_partida'].isin([0,1,2,3,4,5]).astype(int)\n",
        "\n",
        "# Temporadas (aproximación Brasil: verano dic-feb, invierno jun-ago)\n",
        "df['temporada_alta'] = df['mes'].isin([1,2,7,12]).astype(int)\n",
        "\n",
        "# Fin/inicio de mes (más tráfico corporativo)\n",
        "df['fin_inicio_mes'] = df['dia_mes'].isin(list(range(1,6)) + list(range(26,32))).astype(int)\n",
        "\n",
        "# 2.2 ESTADÍSTICAS HISTÓRICAS (Feature Engineering clave)\n",
        "print(\"  → Calculando estadísticas históricas por aerolínea...\")\n",
        "airline_stats = df.groupby('companhia').agg({\n",
        "    'target': ['mean', 'count'],\n",
        "    'delay_minutes': ['mean', 'std']\n",
        "}).reset_index()\n",
        "airline_stats.columns = ['companhia', 'airline_delay_rate', 'airline_flights',\n",
        "                         'airline_avg_delay', 'airline_std_delay']\n",
        "df = df.merge(airline_stats, on='companhia', how='left')\n",
        "\n",
        "print(\"  → Calculando estadísticas por ruta...\")\n",
        "route_stats = df.groupby(['origem', 'destino']).agg({\n",
        "    'target': 'mean',\n",
        "    'delay_minutes': 'mean'\n",
        "}).reset_index()\n",
        "route_stats.columns = ['origem', 'destino', 'route_delay_rate', 'route_avg_delay']\n",
        "df = df.merge(route_stats, on=['origem', 'destino'], how='left')\n",
        "\n",
        "print(\"  → Calculando estadísticas por aeropuerto origen...\")\n",
        "origin_stats = df.groupby('origem').agg({\n",
        "    'target': 'mean',\n",
        "    'delay_minutes': 'count'\n",
        "}).reset_index()\n",
        "origin_stats.columns = ['origem', 'origin_delay_rate', 'origin_flights']\n",
        "df = df.merge(origin_stats, on='origem', how='left')\n",
        "\n",
        "print(\"  → Calculando estadísticas por hora del día...\")\n",
        "hour_stats = df.groupby('hora_partida')['target'].mean().reset_index()\n",
        "hour_stats.columns = ['hora_partida', 'hour_delay_rate']\n",
        "df = df.merge(hour_stats, on='hora_partida', how='left')\n",
        "\n",
        "# 2.3 INTERACCIONES CLAVE\n",
        "print(\"  → Creando variables de interacción...\")\n",
        "df['companhia_origen'] = df['companhia'] + '_' + df['origem']\n",
        "df['hora_dia_semana'] = df['hora_partida'].astype(str) + '_' + df['dia_semana'].astype(str)\n",
        "\n",
        "# 2.4 FEATURES DE VOLUMEN (normalizado)\n",
        "df['airline_popularity'] = df['airline_flights'] / df['airline_flights'].max()\n",
        "df['origin_traffic'] = df['origin_flights'] / df['origin_flights'].max()\n",
        "\n",
        "print(f\"✓ Total de features creadas: {df.shape[1]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 3: CODIFICACIÓN Y PREPARACIÓN FINAL\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"CODIFICANDO VARIABLES CATEGÓRICAS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Encoders\n",
        "le_companhia = LabelEncoder()\n",
        "le_origem = LabelEncoder()\n",
        "le_destino = LabelEncoder()\n",
        "le_comp_orig = LabelEncoder()\n",
        "le_hour_day = LabelEncoder()\n",
        "\n",
        "df['companhia_encoded'] = le_companhia.fit_transform(df['companhia'].astype(str))\n",
        "df['origem_encoded'] = le_origem.fit_transform(df['origem'].astype(str))\n",
        "df['destino_encoded'] = le_destino.fit_transform(df['destino'].astype(str))\n",
        "df['companhia_origen_encoded'] = le_comp_orig.fit_transform(df['companhia_origen'].astype(str))\n",
        "df['hora_dia_encoded'] = le_hour_day.fit_transform(df['hora_dia_semana'].astype(str))\n",
        "\n",
        "# Definir features finales\n",
        "features = [\n",
        "    # Básicas codificadas\n",
        "    'companhia_encoded', 'origem_encoded', 'destino_encoded',\n",
        "    # Temporales\n",
        "    'hora_partida', 'dia_semana', 'mes', 'dia_mes',\n",
        "    'es_fin_semana', 'es_lunes', 'es_viernes', 'es_hora_pico',\n",
        "    'es_madrugada', 'temporada_alta', 'fin_inicio_mes',\n",
        "    # Estadísticas históricas\n",
        "    'airline_delay_rate', 'airline_avg_delay', 'airline_std_delay',\n",
        "    'route_delay_rate', 'route_avg_delay',\n",
        "    'origin_delay_rate', 'hour_delay_rate',\n",
        "    # Interacciones\n",
        "    'companhia_origen_encoded', 'hora_dia_encoded',\n",
        "    # Volumen\n",
        "    'airline_popularity', 'origin_traffic'\n",
        "]\n",
        "\n",
        "X = df[features].fillna(0)  # Rellenar NaN si existen\n",
        "y = df['target']\n",
        "\n",
        "# Split estratificado\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"✓ Training set: {X_train.shape[0]:,} samples\")\n",
        "print(f\"✓ Test set: {X_test.shape[0]:,} samples\")\n",
        "print(f\"✓ Total features: {X_train.shape[1]}\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 4: ENTRENAMIENTO DE MÚLTIPLES MODELOS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ENTRENANDO Y COMPARANDO MODELOS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Configuración de validación cruzada\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Diccionario para guardar resultados\n",
        "results = {}\n",
        "\n",
        "# -----------------------------\n",
        "# MODELO 1: Random Forest Optimizado\n",
        "# -----------------------------\n",
        "print(\"\\n[1/4] Random Forest con búsqueda de hiperparámetros...\")\n",
        "rf_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 15, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'class_weight': ['balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_search = RandomizedSearchCV(\n",
        "    rf, rf_params, n_iter=20, cv=cv, scoring='f1',\n",
        "    random_state=42, n_jobs=-1, verbose=0\n",
        ")\n",
        "rf_search.fit(X_train, y_train)\n",
        "results['Random Forest'] = rf_search.best_estimator_\n",
        "print(f\"  ✓ Mejor F1 (CV): {rf_search.best_score_:.4f}\")\n",
        "print(f\"  ✓ Mejores parámetros: {rf_search.best_params_}\")\n",
        "\n",
        "# -----------------------------\n",
        "# MODELO 2: XGBoost\n",
        "# -----------------------------\n",
        "print(\"\\n[2/4] XGBoost con búsqueda de hiperparámetros...\")\n",
        "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "xgb_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [4, 6, 8, 10],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'scale_pos_weight': [scale_pos_weight]\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss', n_jobs=-1)\n",
        "xgb_search = RandomizedSearchCV(\n",
        "    xgb_model, xgb_params, n_iter=20, cv=cv, scoring='f1',\n",
        "    random_state=42, n_jobs=-1, verbose=0\n",
        ")\n",
        "xgb_search.fit(X_train, y_train)\n",
        "results['XGBoost'] = xgb_search.best_estimator_\n",
        "print(f\"  ✓ Mejor F1 (CV): {xgb_search.best_score_:.4f}\")\n",
        "print(f\"  ✓ Mejores parámetros: {xgb_search.best_params_}\")\n",
        "\n",
        "# -----------------------------\n",
        "# MODELO 3: LightGBM\n",
        "# -----------------------------\n",
        "print(\"\\n[3/4] LightGBM con búsqueda de hiperparámetros...\")\n",
        "lgb_params = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15, -1],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [31, 50, 70],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
        "    'class_weight': ['balanced']\n",
        "}\n",
        "\n",
        "lgb_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1)\n",
        "lgb_search = RandomizedSearchCV(\n",
        "    lgb_model, lgb_params, n_iter=20, cv=cv, scoring='f1',\n",
        "    random_state=42, n_jobs=-1, verbose=0\n",
        ")\n",
        "lgb_search.fit(X_train, y_train)\n",
        "results['LightGBM'] = lgb_search.best_estimator_\n",
        "print(f\"  ✓ Mejor F1 (CV): {lgb_search.best_score_:.4f}\")\n",
        "print(f\"  ✓ Mejores parámetros: {lgb_search.best_params_}\")\n",
        "\n",
        "# -----------------------------\n",
        "# MODELO 4: Logistic Regression (Baseline)\n",
        "# -----------------------------\n",
        "print(\"\\n[4/4] Logistic Regression (baseline rápido)...\")\n",
        "lr = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "results['Logistic Regression'] = lr\n",
        "print(f\"  ✓ Modelo entrenado\")\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 5: EVALUACIÓN Y COMPARACIÓN\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"EVALUANDO MODELOS EN TEST SET...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "comparison = []\n",
        "for name, model in results.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Métricas\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    comparison.append({\n",
        "        'Modelo': name,\n",
        "        'F1-Score': f1,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'ROC-AUC': roc_auc,\n",
        "        'Accuracy': (y_pred == y_test).mean()\n",
        "    })\n",
        "\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  F1-Score: {f1:.4f}\")\n",
        "    print(f\"  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall: {recall:.4f}\")\n",
        "    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
        "    print(f\"  Accuracy: {(y_pred == y_test).mean():.4f}\")\n",
        "\n",
        "# Tabla comparativa\n",
        "comparison_df = pd.DataFrame(comparison).sort_values('F1-Score', ascending=False)\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"RANKING DE MODELOS:\")\n",
        "print(\"=\" * 70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 6: OPTIMIZACIÓN DE THRESHOLD (Mejor modelo)\n",
        "# ============================================================================\n",
        "best_model_name = comparison_df.iloc[0]['Modelo']\n",
        "best_model = results[best_model_name]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(f\"OPTIMIZANDO THRESHOLD PARA: {best_model_name}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba)\n",
        "\n",
        "# Calcular F1 para cada threshold\n",
        "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
        "best_threshold_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_threshold_idx]\n",
        "\n",
        "print(f\"✓ Threshold óptimo: {best_threshold:.4f}\")\n",
        "print(f\"✓ F1-Score óptimo: {f1_scores[best_threshold_idx]:.4f}\")\n",
        "\n",
        "# Predicciones con threshold optimizado\n",
        "y_pred_optimized = (y_proba >= best_threshold).astype(int)\n",
        "\n",
        "print(\"\\n--- COMPARACIÓN: Default (0.5) vs Optimizado ---\")\n",
        "print(\"\\nThreshold 0.5:\")\n",
        "print(classification_report(y_test, best_model.predict(X_test), digits=4))\n",
        "\n",
        "print(f\"\\nThreshold {best_threshold:.4f}:\")\n",
        "print(classification_report(y_test, y_pred_optimized, digits=4))\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 7: ANÁLISIS DETALLADO DEL MEJOR MODELO\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ANÁLISIS DETALLADO Y FEATURE IMPORTANCE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_test, y_pred_optimized)\n",
        "print(\"\\nMatriz de Confusión (threshold optimizado):\")\n",
        "print(cm)\n",
        "print(f\"\\nVerdaderos Negativos: {cm[0,0]:,}\")\n",
        "print(f\"Falsos Positivos: {cm[0,1]:,}\")\n",
        "print(f\"Falsos Negativos: {cm[1,0]:,}\")\n",
        "print(f\"Verdaderos Positivos: {cm[1,1]:,}\")\n",
        "\n",
        "# Feature Importance (si el modelo lo soporta)\n",
        "if hasattr(best_model, 'feature_importances_'):\n",
        "    importances = pd.DataFrame({\n",
        "        'feature': features,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    print(\"\\nTop 15 Features Más Importantes:\")\n",
        "    print(importances.head(15).to_string(index=False))\n",
        "\n",
        "# ============================================================================\n",
        "# PASO 8: GUARDAR MODELO Y ARTEFACTOS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"GUARDANDO MODELO Y ARTEFACTOS...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "artifacts = {\n",
        "    'model': best_model,\n",
        "    'threshold': best_threshold,\n",
        "    'le_companhia': le_companhia,\n",
        "    'le_origem': le_origem,\n",
        "    'le_destino': le_destino,\n",
        "    'le_comp_orig': le_comp_orig,\n",
        "    'le_hour_day': le_hour_day,\n",
        "    'features': features,\n",
        "    'airline_stats': airline_stats,\n",
        "    'route_stats': route_stats,\n",
        "    'origin_stats': origin_stats,\n",
        "    'hour_stats': hour_stats,\n",
        "    'model_name': best_model_name\n",
        "}\n",
        "\n",
        "joblib.dump(artifacts, 'flight_model_optimized_v2.joblib')\n",
        "print(\"✓ Modelo guardado en: flight_model_optimized_v2.joblib\")\n",
        "\n",
        "# Guardar comparación\n",
        "comparison_df.to_csv('model_comparison_results.csv', index=False)\n",
        "print(\"✓ Comparación guardada en: model_comparison_results.csv\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"¡PROCESO COMPLETADO EXITOSAMENTE!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nModelo final: {best_model_name}\")\n",
        "print(f\"F1-Score: {comparison_df.iloc[0]['F1-Score']:.4f}\")\n",
        "print(f\"Recall: {comparison_df.iloc[0]['Recall']:.4f}\")\n",
        "print(f\"Precision: {comparison_df.iloc[0]['Precision']:.4f}\")\n",
        "print(f\"Threshold: {best_threshold:.4f}\")"
      ]
    }
  ]
}